# OSS Data Platform - Cursor Rules

## Project Overview
NBA sports betting data platform. Goal: Build ML models to predict game outcomes for betting.

## ‚ö†Ô∏è CRITICAL: LLM Must Automatically Validate Changes

**When making ANY change to assets, jobs, pipelines, schemas, or tables, the LLM MUST automatically validate using available tools:**

1. **Run Dagster CLI commands** using `run_terminal_cmd` to execute assets/jobs
2. **Query warehouse** using `run_terminal_cmd` with `python scripts/db_query.py` to verify data
3. **Check execution output** for success indicators ("RUN_SUCCESS", "LOADED and contains no failed jobs")
4. **Only mark changes complete** after validation succeeds - if validation fails, fix issues before proceeding

**The LLM should NOT skip validation or assume changes work. Always run the validation commands after making changes.**

## üö´ CONSTRAINT: Free Services Only
**All tools, APIs, and services MUST be free.** No paid subscriptions, API costs, or premium tiers.
- ‚úÖ Free: NBA CDN, open-source tools, free API tiers, scraping (if legal)
- ‚ùå No: Paid APIs, premium subscriptions, usage-based pricing

## Quick Reference
- **Dagster UI**: http://localhost:3000
- **Metabase**: http://localhost:3002
- **PostgreSQL**: localhost:5432 (postgres/postgres/nba_analytics)
- **Database**: `nba_analytics` with layered schemas (raw_dev ‚Üí staging_dev ‚Üí marts_dev ‚Üí features_dev ‚Üí ml_dev)

## Key Commands
```bash
make docker-up         # Start all services
make docker-down       # Stop services
make dagster-dev       # Start local Dagster (uses Docker Postgres)
make db-counts         # Show row counts in raw_dev
make db-schemas        # List all database schemas
make generate-configs  # Generate tool configs from ODCS
```

## Database Query Utility
```bash
# Quick validation queries (use this to check data)
python scripts/db_query.py --counts raw_dev
python scripts/db_query.py --schemas
python scripts/db_query.py "SELECT * FROM raw_dev.teams LIMIT 5"
python scripts/db_query.py "SELECT count(*) FROM raw_dev.games"
```

## Documentation
For detailed context, reference these docs in `.cursor/docs/`:

| Doc | When to Reference |
|-----|-------------------|
| `architecture.md` | Understanding system design, data flow |
| `contracts.md` | ODCS contracts, schema definitions, contract loader |
| `ingestion.md` | Adding new data sources, dlt pipelines |
| `database.md` | Schema structure, tables, useful queries |
| `ml-features.md` | ML model features, betting predictions |
| `commands.md` | Full list of make commands, docker ops |

## Code Locations
- `ingestion/dlt/pipelines/` - dlt data pipelines
- `ingestion/dlt/config.py` - NBA CDN endpoints, constants
- `orchestration/dagster/assets/` - Dagster asset definitions
- `transformation/sqlmesh/` - SQL transformations
- `contracts/schemas/` - ODCS data contracts
- `scripts/db_query.py` - Database query utility

---

## ‚úÖ REQUIRED: LLM Automatic Validation

**‚ö†Ô∏è CRITICAL: The LLM MUST automatically validate changes using available tools (run_terminal_cmd). Do not skip this step.**

**After making ANY change that impacts tables, assets, jobs, or warehouse data, the LLM MUST:**
1. Execute Dagster CLI commands to run the changed asset/job
2. Query the warehouse to verify data loaded correctly
3. Check execution logs for success/failure
4. Only proceed if validation succeeds - otherwise fix issues and re-validate

**Validation should happen automatically as part of the change, not as a separate manual step.**

This includes (but not limited to):
- **New or modified Dagster assets**
- **New or modified Dagster jobs/schedules**
- **Changes to dlt pipelines or resources**
- **Database schema/table changes**
- **Contract/schema modifications**
- **Config changes affecting data ingestion/transformation**
- **SQLMesh model changes**

### Standard Validation Workflow (LLM Should Execute Automatically)

**The LLM must execute these steps automatically after making changes:**

**1. Run the change using Dagster CLI (via run_terminal_cmd):**
```bash
# For assets:
docker exec nba_analytics_dagster_webserver dagster asset materialize -f /app/definitions.py --select <asset_name>

# For jobs:
docker exec nba_analytics_dagster_webserver dagster job execute -f /app/definitions.py -j <job_name>

# Local Dagster (if using make dagster-dev):
dagster asset materialize -f definitions.py --select <asset_name>
dagster job execute -f definitions.py -j <job_name>
```

**2. Verify data in warehouse (via run_terminal_cmd with db_query.py):**
```bash
# Check row counts
python scripts/db_query.py --counts raw_dev
python scripts/db_query.py "SELECT count(*) FROM raw_dev.<table_name>"

# Sample data
python scripts/db_query.py "SELECT * FROM raw_dev.<table_name> LIMIT 5"

# Verify structure
python scripts/db_query.py --schemas
python scripts/db_query.py --tables raw_dev
```

**3. Check execution logs in terminal output:**
- Verify presence of: `"LOADED and contains no failed jobs"` or `"RUN_SUCCESS"`
- Confirm no errors in Dagster output
- Verify expected rows were processed (counts should be reasonable, not zero unless expected)
- **If validation fails, the LLM must fix issues and re-run validation before proceeding**

### Validation by Change Type (LLM Must Execute These)

**The LLM should automatically run these validation commands after making the corresponding changes:**

#### New/Modified Ingestion Asset
**After creating/modifying an ingestion asset, LLM must run:**
```bash
# 1. Run asset via Dagster CLI
docker exec nba_analytics_dagster_webserver dagster asset materialize -f /app/definitions.py --select <asset_name>

# 2. Verify table exists and has data
python scripts/db_query.py "SELECT count(*) FROM raw_dev.<table_name>"
python scripts/db_query.py "SELECT * FROM raw_dev.<table_name> LIMIT 5"

# 3. Check for errors (should see "RUN_SUCCESS" or "LOADED and contains no failed jobs")
```

#### New/Modified Dagster Job or Schedule
**After creating/modifying a job or schedule, LLM must run:**
```bash
# 1. Verify job exists
docker exec nba_analytics_dagster_webserver dagster job list -f /app/definitions.py

# 2. Execute the job
docker exec nba_analytics_dagster_webserver dagster job execute -f /app/definitions.py -j <job_name>

# 3. Verify all assets in job completed successfully
# Check logs for each asset materialization

# 4. Validate affected tables
python scripts/db_query.py --counts raw_dev
```

#### New/Modified dlt Resource or Pipeline
**After creating/modifying a dlt resource or pipeline, LLM must run:**
```bash
# 1. Test extraction locally (optional, for debugging)
python -c "from ingestion.dlt.pipelines.nba_stats import <resource_name>; print(list(<resource_name>())[:3])"

# 2. Run full pipeline via Dagster asset
docker exec nba_analytics_dagster_webserver dagster asset materialize -f /app/definitions.py --select <asset_name>

# 3. Validate data loaded correctly
python scripts/db_query.py --counts raw_dev
python scripts/db_query.py "SELECT * FROM raw_dev.<table_name> LIMIT 5"
```

#### Schema/Contract Changes
**After modifying schemas or contracts, LLM must run:**
```bash
# 1. Run affected asset to create/update table
docker exec nba_analytics_dagster_webserver dagster asset materialize -f /app/definitions.py --select <asset_name>

# 2. Verify schema exists
python scripts/db_query.py --schemas

# 3. Check table structure matches contract
python scripts/db_query.py "SELECT column_name, data_type FROM information_schema.columns WHERE table_schema = 'raw_dev' AND table_name = '<table>' ORDER BY ordinal_position"
```

#### Database Changes (init.sql, schema changes)
**After database changes, LLM must run:**
```bash
# 1. Restart services to apply changes
docker-compose down -v && docker-compose up -d

# 2. Verify schemas created
python scripts/db_query.py --schemas

# 3. Verify tables exist
python scripts/db_query.py --tables raw_dev
python scripts/db_query.py --tables staging_dev
python scripts/db_query.py --tables marts_dev
python scripts/db_query.py --tables features_dev
python scripts/db_query.py --tables ml_dev

# 4. If schema changed, run affected assets
docker exec nba_analytics_dagster_webserver dagster asset materialize -f /app/definitions.py --select <affected_assets>
```

#### SQLMesh Model Changes
**After SQLMesh model changes, LLM must run:**
```bash
# 1. Plan changes
make sqlmesh-plan

# 2. Apply changes
make sqlmesh-run

# 3. Verify data in target schemas
python scripts/db_query.py "SELECT count(*) FROM staging_dev.<table>"
python scripts/db_query.py "SELECT count(*) FROM marts_dev.<table>"
```

### LLM Validation Checklist (Must Complete Automatically)

**The LLM MUST automatically verify these items after making changes (using run_terminal_cmd):**

- [ ] Execute Dagster CLI command - check output shows success (no errors)
- [ ] Query warehouse to verify tables exist in expected schemas
- [ ] Query warehouse to verify row counts are reasonable (not zero unless expected)
- [ ] Query warehouse to verify data structure matches contracts/schemas
- [ ] Query warehouse to sample data and verify it looks correct
- [ ] Parse terminal output to confirm no errors in Dagster logs
- [ ] If job/schedule changed, execute job and verify it completes successfully

**If ANY validation fails, the LLM must:**
1. Identify the issue from terminal output
2. Fix the problem
3. Re-run validation commands
4. Only proceed once all validations pass

**The LLM should NOT skip validation steps or assume changes work without testing.**

---

## üìã REQUIRED: Keep Contracts Updated

**When adding new schemas or modifying existing ones, ALWAYS recompose contracts:**

```bash
# After ANY change to contracts/schemas/*.yml:
make compose-contracts

# Verify all contracts exist
ls contracts/contracts/
```

### Contract Workflow
1. Edit schema in `contracts/schemas/<name>.yml`
2. Run `make compose-contracts` to generate composed contract
3. Verify `contracts/contracts/<name>.yml` was created/updated
4. If adding new asset, also update `configs/odcs/datasets.yml`

### Current Contracts (must match schemas/)
```
contracts/schemas/           contracts/contracts/
‚îú‚îÄ‚îÄ nba_betting_odds.yml  ‚Üí ‚îú‚îÄ‚îÄ nba_betting_odds.yml
‚îú‚îÄ‚îÄ nba_boxscores.yml     ‚Üí ‚îú‚îÄ‚îÄ nba_boxscores.yml
‚îú‚îÄ‚îÄ nba_games.yml         ‚Üí ‚îú‚îÄ‚îÄ nba_games.yml
‚îú‚îÄ‚îÄ nba_players.yml       ‚Üí ‚îú‚îÄ‚îÄ nba_players.yml
‚îú‚îÄ‚îÄ nba_teams.yml         ‚Üí ‚îú‚îÄ‚îÄ nba_teams.yml
‚îú‚îÄ‚îÄ nba_todays_games.yml  ‚Üí ‚îú‚îÄ‚îÄ nba_todays_games.yml
‚îî‚îÄ‚îÄ ...                   ‚Üí ‚îî‚îÄ‚îÄ ...
```

---

## ‚ö†Ô∏è IMPORTANT: Documentation Maintenance

**After making changes, UPDATE THE RELEVANT DOCS in `.cursor/docs/`:**

| Change Type | Docs to Update |
|-------------|----------------|
| Database schema changes | `database.md` |
| New tables/schemas | `database.md`, `architecture.md` |
| New make commands | `commands.md`, this file |
| New data sources/endpoints | `ingestion.md`, `config.py` |
| New contracts/schemas | `contracts.md` |
| New assets/pipelines | `ingestion.md`, `architecture.md` |
| ML features/models | `ml-features.md` |
| Config changes | `commands.md` (env vars), relevant doc |

**Checklist after significant changes:**
1. [ ] Update relevant `.cursor/docs/*.md` files
2. [ ] Update this `.cursorrules` quick reference if needed
3. [ ] Update `README.md` if user-facing workflow changed
4. [ ] Add/update docstrings in code

**Keep docs in sync with reality - outdated docs are worse than no docs.**

---

## üó∫Ô∏è Development Roadmap

### ‚úÖ Phase 1: ML Pipeline (Current Focus)

**Status**: ML training and prediction assets created. Next: Validate and test.

**Completed:**
- ‚úÖ Training asset (`train_game_winner_model`) - XGBoost model training
- ‚úÖ Prediction asset (`generate_game_predictions`) - Generate predictions for upcoming games
- ‚úÖ ML infrastructure - `ml_dev` schema with model_registry, predictions, betting_results tables

**Next Immediate Steps:**
1. [ ] Validate ML assets - Run training asset, verify model saved and registered in `ml_dev.model_registry`
2. [ ] Test predictions - Generate predictions for upcoming games, verify stored in `ml_dev.predictions`
3. [ ] Model evaluation - Track accuracy, compare predictions vs. actuals

**Reference**: See `.cursor/docs/ml-features.md` for detailed ML feature documentation.

### üîÆ Phase 2: Expand ML Pipeline (Future Enhancements)

**Priority**: After Phase 1 validation is complete.

**Multiple Models:**
- [ ] **Spread prediction model** - Predict point spread outcomes (requires historical odds)
- [ ] **Over/Under model** - Predict total points over/under (requires historical odds)
- [ ] **Player prop models** - Individual player performance predictions

**Model Evaluation & Comparison:**
- [ ] **Model evaluation asset** - Compare predictions vs. actual outcomes, calculate metrics (accuracy, precision, recall, F1)
- [ ] **A/B testing** - Compare different algorithms (XGBoost vs. Neural Networks vs. Logistic Regression)
- [ ] **Feature importance analysis** - Understand which features drive predictions (SHAP values)
- [ ] **Backtesting framework** - Historical performance simulation, P&L tracking

**Advanced MLOps:**
- [ ] **Hyperparameter tuning** - Automated optimization using Optuna/Hyperopt
- [ ] **Model monitoring** - Track prediction drift, feature drift over time
- [ ] **Automated retraining triggers** - Retrain when accuracy drops below threshold
- [ ] **Model explainability** - SHAP values, feature contributions per prediction

**Reference**: See `.cursor/docs/ml-features.md` section "Future ML Enhancements".

### üìä Phase 3: Data Quality Integration (After ML Pipeline)

**Priority**: After ML pipeline is validated and running.

**Baselinr Integration:**
- [ ] **Regenerate Baselinr config** - Fix `configs/generated/baselinr/baselinr_config.yml`
  - Update database name (`oss_data_platform` ‚Üí `nba_analytics`)
  - Update table references to `raw_dev.*` schemas (currently references wrong tables)
  - Remove outdated `customer_orders` table references
  - Add quality rules for NBA data (nullability, ranges, uniqueness)
- [ ] **Wire quality assets** - Ensure `quality` assets load correctly in Dagster definitions
- [ ] **Quality checks on features** - Monitor `features_dev.*` tables for drift, anomalies
- [ ] **Quality checks on predictions** - Validate prediction confidence, feature completeness

**Data Validation:**
- [ ] **Schema validation** - Ensure features match training schema before model input
- [ ] **Data freshness checks** - Alert when features are stale (games older than X days)
- [ ] **Missing feature detection** - Identify games with incomplete features

**Reference**: See `.cursor/docs/ml-features.md` section "Data Quality Integration".

### üìã Ongoing: Data Gaps (Free Sources Only)

**Constraint**: All data sources must be FREE. No paid APIs.

**Remaining Gaps:**
- [ ] **Historical betting odds** - Building daily via `nba_betting_odds` asset (long-term accumulation)
- [ ] **Advanced stats** - Calculate from existing data (Pace, OffRtg, DefRtg, eFG%, TS%) - add to SQLMesh transformations
- [ ] **Rest/travel data** - Calculate from schedule (back-to-backs, travel distance) - add to feature engineering

**Reference**: See `.cursor/docs/ml-features.md` section "Remaining Data Gaps".

---

**Note**: When starting work on any phase, check `.cursor/docs/ml-features.md` for current status and detailed requirements.
